# ğŸ§  Behavior, Difficulty & Grading: What Drives Retention on Lernnavi?

This repository contains the code, data processing scripts

## ğŸ“˜ Overview

Learner dropout remains a central challenge in online education platforms. This project analyzes user engagement on **Lernnavi**, a curriculum-aligned learning platform used in Swiss secondary schools, to understand what factors most influence student retention.

We investigate:

1. **Behavioral Profiles** â€” How do user activity patterns affect next-week engagement?  
2. **Perceived Difficulty** â€” Can task complexity predict dropout?  
3. **Grading Bias** â€” Are open-ended responses evaluated fairly?

## ğŸ§° Methodology

- **Behavior Profiling**: Aggregated event logs into weekly features, grouped into six dimensions of self-regulated learning.  
- **Engagement Prediction**: Time-aware classification using tree-based models and LSTM.  
- **Difficulty Modeling**: Constructed difficulty features from user response time and task correctness.  
- **Bias Detection**: Compared grading outcomes with semantic similarity-based oracle labels using multilingual SBERT.

## ğŸ§ª Key Findings

- **Effort and regularity** dominate engagement prediction.  
- **Difficulty features alone** are weak predictors of dropout.  
- **Misalignments** in grading open-input questions suggest areas for improvement in evaluation consistency.

## ğŸ“‚ Project Structure

<pre lang="markdown"><code> ``` â”œâ”€â”€ data/ # Raw and processed Lernnavi data â”œâ”€â”€ figures/ # Plots used in the final report â”œâ”€â”€ models/ # Trained models and clustering artifacts â”œâ”€â”€ src/ # Scripts for feature engineering, training, and evaluation â”œâ”€â”€ paper/ # LaTeX source code for the report â”‚ â””â”€â”€ lernnavi_report.tex â”œâ”€â”€ requirements.txt # Python dependencies â””â”€â”€ README.md # Project documentation ``` </code></pre>

## ğŸ‘©â€ğŸ”¬ Authors
 Valentine Casalta
 Omar Boudarka
 Nino Gerber
